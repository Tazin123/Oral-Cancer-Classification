{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a86f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in c:\\users\\shusmita\\anaconda3\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\shusmita\\anaconda3\\lib\\site-packages (from tensorflow-hub) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\shusmita\\anaconda3\\lib\\site-packages (from tensorflow-hub) (4.23.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2e1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93df773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839af658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328fe071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom classification layers on top\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # For binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335424b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6186f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591d179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy','Precision','Recall','AUC']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b979f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "classes = 'binary'\n",
    "\n",
    "train='C:/Users/Shusmita/Desktop/Oral Cancer/Augmented_Oral_Cancer/train'\n",
    "test='C:/Users/Shusmita\\Desktop\\Oral Cancer/Augmented_Oral_Cancer/test'\n",
    "val='C:/Users/Shusmita/Desktop/Oral Cancer/Augmented_Oral_Cancer/Validate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58081a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 619 images belonging to 2 classes.\n",
      "Found 130 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "validation_datagen= image.ImageDataGenerator()\n",
    "\n",
    "test_datagen= image.ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train,\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch,\n",
    "    class_mode = classes)\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val,\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch,\n",
    "    shuffle=True,\n",
    "    class_mode = classes)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size = (224,224),\n",
    "    batch_size = batch,\n",
    "    class_mode = classes)\n",
    "class_names=validation_generator.class_indices\n",
    "class_names\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f86c272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 212s 11s/step - loss: 18.2261 - accuracy: 0.7092 - precision: 0.7079 - recall: 0.7170 - auc: 0.7191 - val_loss: 5.7456 - val_accuracy: 0.8308 - val_precision: 1.0000 - val_recall: 0.6562 - val_auc: 0.8414\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 232s 12s/step - loss: 2.7617 - accuracy: 0.8611 - precision: 0.8689 - recall: 0.8521 - auc: 0.8804 - val_loss: 1.8216 - val_accuracy: 0.8846 - val_precision: 1.0000 - val_recall: 0.7656 - val_auc: 0.9048\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 214s 11s/step - loss: 1.4864 - accuracy: 0.8982 - precision: 0.9161 - recall: 0.8778 - auc: 0.9192 - val_loss: 0.3927 - val_accuracy: 0.9462 - val_precision: 0.9524 - val_recall: 0.9375 - val_auc: 0.9580\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 205s 10s/step - loss: 0.4893 - accuracy: 0.9128 - precision: 0.8978 - recall: 0.9325 - auc: 0.9599 - val_loss: 0.3028 - val_accuracy: 0.9538 - val_precision: 0.9833 - val_recall: 0.9219 - val_auc: 0.9725\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 215s 11s/step - loss: 0.4013 - accuracy: 0.9257 - precision: 0.9260 - recall: 0.9260 - auc: 0.9635 - val_loss: 0.3018 - val_accuracy: 0.9154 - val_precision: 1.0000 - val_recall: 0.8281 - val_auc: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 5  # You can adjust the number of epochs\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ae9c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 34s 7s/step - loss: 0.3018 - accuracy: 0.9154 - precision: 1.0000 - recall: 0.8281 - auc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3018408417701721, 0.9153845906257629, 1.0, 0.828125, 0.9901752471923828]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=model.evaluate(validation_generator)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e427bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 35s 7s/step - loss: 0.4179 - accuracy: 0.9429 - precision: 0.9853 - recall: 0.9054 - auc: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4178904891014099,\n",
       " 0.9428571462631226,\n",
       " 0.9852941036224365,\n",
       " 0.9054054021835327,\n",
       " 0.9699017405509949]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=model.evaluate(test_generator)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba5d2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 169s 8s/step - loss: 0.1574 - accuracy: 0.9532 - precision: 0.9796 - recall: 0.9260 - auc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1573716551065445,\n",
       " 0.95315021276474,\n",
       " 0.9795918464660645,\n",
       " 0.9260450005531311,\n",
       " 0.9887093901634216]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=model.evaluate(train_generator)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
